---
sidebar_position: 4
---

# Module 4 â€“ Vision-Language-Action (VLA)

Welcome to Module 4! This module covers cutting-edge Vision-Language-Action models for humanoid robotics, enabling natural language control and advanced AI capabilities.

## What You'll Learn

- Whisper speech recognition integration
- Large Language Models (LLMs) for robot control
- Vision-Language-Action pipelines
- Building complete AI-powered robot systems

## Chapters

1. [Chapter 1: Whisper & LLMs](./chapter-1-whisper-llms.md)
2. [Chapter 2: Full Capstone Pipeline](./chapter-2-capstone-pipeline.md)

## Learning Objectives

By the end of this module, you will be able to:
- Integrate speech recognition using Whisper
- Connect LLMs to robot control systems
- Build Vision-Language-Action pipelines
- Create complete AI-powered humanoid robot applications
